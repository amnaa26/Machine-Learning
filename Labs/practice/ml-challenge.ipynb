{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "d7ccfdd4-28ca-4055-bc65-da3a6bd9824b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "676bc4d3-8535-4f0f-8e33-8be43994bb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Rainfall-tom-ml.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "766ccdeb-6bae-4eeb-b6e9-1ca4550436db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>pressure</th>\n",
       "      <th>maxtemp</th>\n",
       "      <th>temparature</th>\n",
       "      <th>mintemp</th>\n",
       "      <th>dewpoint</th>\n",
       "      <th>humidity</th>\n",
       "      <th>cloud</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>sunshine</th>\n",
       "      <th>winddirection</th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1025.9</td>\n",
       "      <td>19.9</td>\n",
       "      <td>18.3</td>\n",
       "      <td>16.8</td>\n",
       "      <td>13.1</td>\n",
       "      <td>72</td>\n",
       "      <td>49</td>\n",
       "      <td>yes</td>\n",
       "      <td>9.3</td>\n",
       "      <td>80.0</td>\n",
       "      <td>26.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>21.7</td>\n",
       "      <td>18.9</td>\n",
       "      <td>17.2</td>\n",
       "      <td>15.6</td>\n",
       "      <td>81</td>\n",
       "      <td>83</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50.0</td>\n",
       "      <td>15.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1019.7</td>\n",
       "      <td>20.3</td>\n",
       "      <td>19.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>95</td>\n",
       "      <td>91</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>14.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1018.9</td>\n",
       "      <td>22.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>19.1</td>\n",
       "      <td>18.8</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>16.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1015.9</td>\n",
       "      <td>21.3</td>\n",
       "      <td>20.7</td>\n",
       "      <td>20.2</td>\n",
       "      <td>19.9</td>\n",
       "      <td>95</td>\n",
       "      <td>81</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>13.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   day  pressure   maxtemp  temparature  mintemp  dewpoint  humidity   cloud   \\\n",
       "0    1     1025.9     19.9         18.3     16.8      13.1         72      49   \n",
       "1    2     1022.0     21.7         18.9     17.2      15.6         81      83   \n",
       "2    3     1019.7     20.3         19.3     18.0      18.4         95      91   \n",
       "3    4     1018.9     22.3         20.6     19.1      18.8         90      88   \n",
       "4    5     1015.9     21.3         20.7     20.2      19.9         95      81   \n",
       "\n",
       "  rainfall  sunshine           winddirection  windspeed  \n",
       "0      yes       9.3                    80.0       26.3  \n",
       "1      yes       0.6                    50.0       15.3  \n",
       "2      yes       0.0                    40.0       14.2  \n",
       "3      yes       1.0                    50.0       16.9  \n",
       "4      yes       0.0                    40.0       13.7  "
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "04235d2e-42a7-424b-9eed-295f18edbbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 366 entries, 0 to 365\n",
      "Data columns (total 12 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   day                     366 non-null    int64  \n",
      " 1   pressure                366 non-null    float64\n",
      " 2   maxtemp                 366 non-null    float64\n",
      " 3   temparature             366 non-null    float64\n",
      " 4   mintemp                 366 non-null    float64\n",
      " 5   dewpoint                366 non-null    float64\n",
      " 6   humidity                366 non-null    int64  \n",
      " 7   cloud                   366 non-null    int64  \n",
      " 8   rainfall                366 non-null    object \n",
      " 9   sunshine                366 non-null    float64\n",
      " 10           winddirection  365 non-null    float64\n",
      " 11  windspeed               365 non-null    float64\n",
      "dtypes: float64(8), int64(3), object(1)\n",
      "memory usage: 34.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "888fa3af-27b6-4aa5-86cb-6a45fa247b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "day                       0\n",
       "pressure                  0\n",
       "maxtemp                   0\n",
       "temparature               0\n",
       "mintemp                   0\n",
       "dewpoint                  0\n",
       "humidity                  0\n",
       "cloud                     0\n",
       "rainfall                  0\n",
       "sunshine                  0\n",
       "         winddirection    1\n",
       "windspeed                 1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "c4933606-7e0e-49a6-8992-dd4274bd6d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'         winddirection': 'winddirection'}, inplace=True)\n",
    "df.rename(columns={'temparature': 'temperature'}, inplace=True)\n",
    "df.columns = df.columns.str.strip()\n",
    "#df.rename(columns= {'old_name': 'new_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e4624c0c-f574-4eea-8e13-13dc1b020709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert windspeed to numeric\n",
    "df['windspeed'] = pd.to_numeric(df['windspeed'], errors='coerce')\n",
    "\n",
    "# Fill missing windspeed with median\n",
    "df['windspeed'].fillna(df['windspeed'].median(), inplace=True)\n",
    "\n",
    "# Wind direction: convert to string and replace missing with \"Unknown\"\n",
    "df['winddirection'] = df['winddirection'].astype(str)\n",
    "df.loc[df['winddirection'].isin(['nan', 'None', '', 'NaN']), 'winddirection'] = np.nan\n",
    "df['winddirection'].fillna(\"Unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "6483845c-9a62-4b43-aa3a-cae032a090b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "15ee49f8-82e3-4a4f-ac1f-c6bd6b7f113e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "day              0\n",
       "pressure         0\n",
       "maxtemp          0\n",
       "temperature      0\n",
       "mintemp          0\n",
       "dewpoint         0\n",
       "humidity         0\n",
       "cloud            0\n",
       "rainfall         0\n",
       "sunshine         0\n",
       "winddirection    0\n",
       "windspeed        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "3f7d2463-1325-4074-abfc-b1eefb3772e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['day', 'pressure', 'maxtemp', 'temperature', 'mintemp', 'dewpoint',\n",
       "       'humidity', 'cloud', 'rainfall', 'sunshine', 'winddirection',\n",
       "       'windspeed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "cac664e5-e268-44f4-9060-44152d07b442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 365 entries, 0 to 365\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   day            365 non-null    int64  \n",
      " 1   pressure       365 non-null    float64\n",
      " 2   maxtemp        365 non-null    float64\n",
      " 3   temperature    365 non-null    float64\n",
      " 4   mintemp        365 non-null    float64\n",
      " 5   dewpoint       365 non-null    float64\n",
      " 6   humidity       365 non-null    float64\n",
      " 7   cloud          365 non-null    float64\n",
      " 8   rainfall       365 non-null    int64  \n",
      " 9   sunshine       365 non-null    float64\n",
      " 10  winddirection  365 non-null    float64\n",
      " 11  windspeed      365 non-null    float64\n",
      "dtypes: float64(10), int64(2)\n",
      "memory usage: 37.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "656abf65-6da4-46cc-b244-d4b7f08f7893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             pressure   maxtemp  temperature   mintemp  dewpoint  humidity  \\\n",
      "pressure     1.000000 -0.828670    -0.851628 -0.839583 -0.859880 -0.273631   \n",
      "maxtemp     -0.828670  1.000000     0.986189  0.961461  0.899588  0.020450   \n",
      "temperature -0.851628  0.986189     1.000000  0.990173  0.936769  0.090893   \n",
      "mintemp     -0.839583  0.961461     0.990173  1.000000  0.944409  0.137901   \n",
      "dewpoint    -0.859880  0.899588     0.936769  0.944409  1.000000  0.424493   \n",
      "humidity    -0.273631  0.020450     0.090893  0.137901  0.424493  1.000000   \n",
      "cloud        0.006881 -0.291071    -0.206894 -0.157112  0.043753  0.655338   \n",
      "sunshine    -0.196850  0.506863     0.419919  0.367565  0.184151 -0.564896   \n",
      "windspeed    0.374046 -0.442357    -0.393739 -0.359130 -0.378435 -0.076613   \n",
      "\n",
      "                cloud  sunshine  windspeed  \n",
      "pressure     0.006881 -0.196850   0.374046  \n",
      "maxtemp     -0.291071  0.506863  -0.442357  \n",
      "temperature -0.206894  0.419919  -0.393739  \n",
      "mintemp     -0.157112  0.367565  -0.359130  \n",
      "dewpoint     0.043753  0.184151  -0.378435  \n",
      "humidity     0.655338 -0.564896  -0.076613  \n",
      "cloud        1.000000 -0.849337   0.258400  \n",
      "sunshine    -0.849337  1.000000  -0.298892  \n",
      "windspeed    0.258400 -0.298892   1.000000  \n"
     ]
    }
   ],
   "source": [
    "# List numeric columns\n",
    "numeric_cols = ['pressure', 'maxtemp', 'temperature', 'mintemp',\n",
    "                'dewpoint', 'humidity', 'cloud', 'sunshine', 'windspeed']\n",
    "\n",
    "# Convert numeric columns to float\n",
    "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "corr = df[numeric_cols].corr()\n",
    "print(corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "61a90c05-31f5-4ab2-b060-fa8538403768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highly correlated features to drop: ['temperature', 'mintemp', 'dewpoint']\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = ['pressure', 'maxtemp', 'temperature', 'mintemp',\n",
    "                'dewpoint', 'humidity', 'cloud', 'sunshine', 'windspeed']\n",
    "\n",
    "corr = df[numeric_cols].corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "\n",
    "# Find features with correlation > 0.90\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.90)]\n",
    "\n",
    "print(\"Highly correlated features to drop:\", to_drop)\n",
    "\n",
    "df = df.drop(columns=to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "e514377d-c3b8-40aa-9734-7a480d706051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>pressure</th>\n",
       "      <th>maxtemp</th>\n",
       "      <th>temperature</th>\n",
       "      <th>mintemp</th>\n",
       "      <th>dewpoint</th>\n",
       "      <th>humidity</th>\n",
       "      <th>cloud</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>sunshine</th>\n",
       "      <th>winddirection</th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1025.9</td>\n",
       "      <td>19.9</td>\n",
       "      <td>18.3</td>\n",
       "      <td>16.8</td>\n",
       "      <td>13.1</td>\n",
       "      <td>72</td>\n",
       "      <td>49</td>\n",
       "      <td>yes</td>\n",
       "      <td>9.3</td>\n",
       "      <td>80.0</td>\n",
       "      <td>26.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>21.7</td>\n",
       "      <td>18.9</td>\n",
       "      <td>17.2</td>\n",
       "      <td>15.6</td>\n",
       "      <td>81</td>\n",
       "      <td>83</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50.0</td>\n",
       "      <td>15.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1019.7</td>\n",
       "      <td>20.3</td>\n",
       "      <td>19.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>95</td>\n",
       "      <td>91</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>14.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1018.9</td>\n",
       "      <td>22.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>19.1</td>\n",
       "      <td>18.8</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>16.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1015.9</td>\n",
       "      <td>21.3</td>\n",
       "      <td>20.7</td>\n",
       "      <td>20.2</td>\n",
       "      <td>19.9</td>\n",
       "      <td>95</td>\n",
       "      <td>81</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>13.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   day  pressure  maxtemp  temperature  mintemp  dewpoint  humidity  cloud  \\\n",
       "0    1    1025.9     19.9         18.3     16.8      13.1        72     49   \n",
       "1    2    1022.0     21.7         18.9     17.2      15.6        81     83   \n",
       "2    3    1019.7     20.3         19.3     18.0      18.4        95     91   \n",
       "3    4    1018.9     22.3         20.6     19.1      18.8        90     88   \n",
       "4    5    1015.9     21.3         20.7     20.2      19.9        95     81   \n",
       "\n",
       "  rainfall  sunshine  winddirection  windspeed  \n",
       "0      yes       9.3           80.0       26.3  \n",
       "1      yes       0.6           50.0       15.3  \n",
       "2      yes       0.0           40.0       14.2  \n",
       "3      yes       1.0           50.0       16.9  \n",
       "4      yes       0.0           40.0       13.7  "
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "a60b211f-a677-479c-b712-88e86f0de202",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "continuous_features = [\n",
    "    'pressure', 'maxtemp', 'temperature', 'mintemp',\n",
    "    'dewpoint', 'humidity', 'cloud', 'sunshine', 'windspeed'\n",
    "]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df[continuous_features] = scaler.fit_transform(df[continuous_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "de663e33-f9ab-4b85-bbe9-5b06e9ab2b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rainfall'] = df['rainfall'].map({'yes': 1, 'no': 0})\n",
    "#df['column_name'] = df['column_name'].replace({'yes': 1, 'no': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "83334d8a-0d14-48c6-a786-3f9ff46f9a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>pressure</th>\n",
       "      <th>maxtemp</th>\n",
       "      <th>temperature</th>\n",
       "      <th>mintemp</th>\n",
       "      <th>dewpoint</th>\n",
       "      <th>humidity</th>\n",
       "      <th>cloud</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>sunshine</th>\n",
       "      <th>winddirection</th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.759003</td>\n",
       "      <td>0.438356</td>\n",
       "      <td>0.487273</td>\n",
       "      <td>0.509294</td>\n",
       "      <td>0.498155</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1</td>\n",
       "      <td>0.768595</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.397459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.650970</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.509091</td>\n",
       "      <td>0.524164</td>\n",
       "      <td>0.590406</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1</td>\n",
       "      <td>0.049587</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.197822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.587258</td>\n",
       "      <td>0.452055</td>\n",
       "      <td>0.523636</td>\n",
       "      <td>0.553903</td>\n",
       "      <td>0.693727</td>\n",
       "      <td>0.951613</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.177858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.565097</td>\n",
       "      <td>0.520548</td>\n",
       "      <td>0.570909</td>\n",
       "      <td>0.594796</td>\n",
       "      <td>0.708487</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0.082645</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.226860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.481994</td>\n",
       "      <td>0.486301</td>\n",
       "      <td>0.574545</td>\n",
       "      <td>0.635688</td>\n",
       "      <td>0.749077</td>\n",
       "      <td>0.951613</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.168784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.562327</td>\n",
       "      <td>0.589041</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>0.598513</td>\n",
       "      <td>0.678967</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.183303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.645429</td>\n",
       "      <td>0.489726</td>\n",
       "      <td>0.505455</td>\n",
       "      <td>0.516729</td>\n",
       "      <td>0.568266</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0.280992</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.310345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.617729</td>\n",
       "      <td>0.476027</td>\n",
       "      <td>0.490909</td>\n",
       "      <td>0.498141</td>\n",
       "      <td>0.546125</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.179673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.612188</td>\n",
       "      <td>0.404110</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.520446</td>\n",
       "      <td>0.542435</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.633394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.390411</td>\n",
       "      <td>0.476364</td>\n",
       "      <td>0.524164</td>\n",
       "      <td>0.586716</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.604356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.498615</td>\n",
       "      <td>0.455479</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.498141</td>\n",
       "      <td>0.619926</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0.173554</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.343013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.592798</td>\n",
       "      <td>0.390411</td>\n",
       "      <td>0.450909</td>\n",
       "      <td>0.483271</td>\n",
       "      <td>0.520295</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0</td>\n",
       "      <td>0.049587</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.353902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.617729</td>\n",
       "      <td>0.397260</td>\n",
       "      <td>0.407273</td>\n",
       "      <td>0.412639</td>\n",
       "      <td>0.461255</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.752066</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.362976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.576177</td>\n",
       "      <td>0.356164</td>\n",
       "      <td>0.421818</td>\n",
       "      <td>0.464684</td>\n",
       "      <td>0.490775</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1</td>\n",
       "      <td>0.123967</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.522686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.468144</td>\n",
       "      <td>0.308219</td>\n",
       "      <td>0.370909</td>\n",
       "      <td>0.423792</td>\n",
       "      <td>0.553506</td>\n",
       "      <td>0.983871</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.600726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.415512</td>\n",
       "      <td>0.342466</td>\n",
       "      <td>0.418182</td>\n",
       "      <td>0.460967</td>\n",
       "      <td>0.590406</td>\n",
       "      <td>0.951613</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.646098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.360111</td>\n",
       "      <td>0.462329</td>\n",
       "      <td>0.469091</td>\n",
       "      <td>0.434944</td>\n",
       "      <td>0.608856</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1</td>\n",
       "      <td>0.132231</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.344828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.515235</td>\n",
       "      <td>0.366438</td>\n",
       "      <td>0.374545</td>\n",
       "      <td>0.327138</td>\n",
       "      <td>0.424354</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0</td>\n",
       "      <td>0.322314</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.435572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.598338</td>\n",
       "      <td>0.359589</td>\n",
       "      <td>0.418182</td>\n",
       "      <td>0.453532</td>\n",
       "      <td>0.476015</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0.082645</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.609800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.584488</td>\n",
       "      <td>0.332192</td>\n",
       "      <td>0.385455</td>\n",
       "      <td>0.434944</td>\n",
       "      <td>0.527675</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.838475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.531856</td>\n",
       "      <td>0.342466</td>\n",
       "      <td>0.407273</td>\n",
       "      <td>0.446097</td>\n",
       "      <td>0.579336</td>\n",
       "      <td>0.951613</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.395644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.565097</td>\n",
       "      <td>0.311644</td>\n",
       "      <td>0.334545</td>\n",
       "      <td>0.267658</td>\n",
       "      <td>0.490775</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.560799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.792244</td>\n",
       "      <td>0.113014</td>\n",
       "      <td>0.130909</td>\n",
       "      <td>0.144981</td>\n",
       "      <td>0.140221</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.927405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095941</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.944598</td>\n",
       "      <td>0.126712</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.044610</td>\n",
       "      <td>0.151292</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.834711</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.441016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0.792244</td>\n",
       "      <td>0.219178</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.185874</td>\n",
       "      <td>0.107011</td>\n",
       "      <td>0.370968</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1</td>\n",
       "      <td>0.033058</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.306715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0.670360</td>\n",
       "      <td>0.280822</td>\n",
       "      <td>0.294545</td>\n",
       "      <td>0.249071</td>\n",
       "      <td>0.442804</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016529</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.457350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0.545706</td>\n",
       "      <td>0.352740</td>\n",
       "      <td>0.407273</td>\n",
       "      <td>0.434944</td>\n",
       "      <td>0.594096</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.442831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0.537396</td>\n",
       "      <td>0.352740</td>\n",
       "      <td>0.425455</td>\n",
       "      <td>0.475836</td>\n",
       "      <td>0.601476</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016529</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.373866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0.595568</td>\n",
       "      <td>0.438356</td>\n",
       "      <td>0.461818</td>\n",
       "      <td>0.486989</td>\n",
       "      <td>0.586716</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.304900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    day  pressure   maxtemp  temperature   mintemp  dewpoint  humidity  cloud  \\\n",
       "0     1  0.759003  0.438356     0.487273  0.509294  0.498155  0.580645   0.49   \n",
       "1     2  0.650970  0.500000     0.509091  0.524164  0.590406  0.725806   0.83   \n",
       "2     3  0.587258  0.452055     0.523636  0.553903  0.693727  0.951613   0.91   \n",
       "3     4  0.565097  0.520548     0.570909  0.594796  0.708487  0.870968   0.88   \n",
       "4     5  0.481994  0.486301     0.574545  0.635688  0.749077  0.951613   0.81   \n",
       "5     6  0.562327  0.589041     0.581818  0.598513  0.678967  0.774194   0.51   \n",
       "6     7  0.645429  0.489726     0.505455  0.516729  0.568266  0.693548   0.56   \n",
       "7     8  0.617729  0.476027     0.490909  0.498141  0.546125  0.677419   0.28   \n",
       "8     9  0.612188  0.404110     0.480000  0.520446  0.542435  0.677419   0.79   \n",
       "9    10  0.526316  0.390411     0.476364  0.524164  0.586716  0.790323   0.91   \n",
       "10   11  0.498615  0.455479     0.480000  0.498141  0.619926  0.870968   0.90   \n",
       "11   12  0.592798  0.390411     0.450909  0.483271  0.520295  0.693548   0.86   \n",
       "12   13  0.617729  0.397260     0.407273  0.412639  0.461255  0.661290   0.34   \n",
       "13   14  0.576177  0.356164     0.421818  0.464684  0.490775  0.693548   0.81   \n",
       "14   15  0.468144  0.308219     0.370909  0.423792  0.553506  0.983871   0.97   \n",
       "15   16  0.415512  0.342466     0.418182  0.460967  0.590406  0.951613   0.93   \n",
       "16   17  0.360111  0.462329     0.469091  0.434944  0.608856  0.870968   0.79   \n",
       "17   18  0.515235  0.366438     0.374545  0.327138  0.424354  0.645161   0.49   \n",
       "18   19  0.598338  0.359589     0.418182  0.453532  0.476015  0.677419   0.84   \n",
       "19   20  0.584488  0.332192     0.385455  0.434944  0.527675  0.870968   0.92   \n",
       "20   21  0.531856  0.342466     0.407273  0.446097  0.579336  0.951613   1.00   \n",
       "21   22  0.565097  0.311644     0.334545  0.267658  0.490775  0.903226   1.00   \n",
       "22   23  0.792244  0.113014     0.130909  0.144981  0.140221  0.548387   0.95   \n",
       "23   24  1.000000  0.000000     0.000000  0.000000  0.095941  0.403226   0.96   \n",
       "24   25  0.944598  0.126712     0.090909  0.044610  0.151292  0.161290   0.25   \n",
       "25   26  0.792244  0.219178     0.200000  0.185874  0.107011  0.370968   0.85   \n",
       "26   27  0.670360  0.280822     0.294545  0.249071  0.442804  0.903226   0.95   \n",
       "27   28  0.545706  0.352740     0.407273  0.434944  0.594096  1.000000   1.00   \n",
       "28   29  0.537396  0.352740     0.425455  0.475836  0.601476  0.967742   0.91   \n",
       "29   30  0.595568  0.438356     0.461818  0.486989  0.586716  0.838710   0.80   \n",
       "\n",
       "    rainfall  sunshine  winddirection  windspeed  \n",
       "0          1  0.768595           80.0   0.397459  \n",
       "1          1  0.049587           50.0   0.197822  \n",
       "2          1  0.000000           40.0   0.177858  \n",
       "3          1  0.082645           50.0   0.226860  \n",
       "4          1  0.000000           40.0   0.168784  \n",
       "5          1  0.636364           20.0   0.183303  \n",
       "6          0  0.280992           30.0   0.310345  \n",
       "7          0  0.636364           60.0   0.179673  \n",
       "8          0  0.272727           70.0   0.633394  \n",
       "9          1  0.000000           70.0   0.604356  \n",
       "10         1  0.173554           40.0   0.343013  \n",
       "11         0  0.049587           20.0   0.353902  \n",
       "12         0  0.752066           30.0   0.362976  \n",
       "13         1  0.123967           60.0   0.522686  \n",
       "14         1  0.000000           50.0   0.600726  \n",
       "15         1  0.000000           60.0   0.646098  \n",
       "16         1  0.132231           20.0   0.344828  \n",
       "17         0  0.322314           50.0   0.435572  \n",
       "18         0  0.082645           60.0   0.609800  \n",
       "19         1  0.000000           70.0   0.838475  \n",
       "20         1  0.000000           50.0   0.395644  \n",
       "21         1  0.000000           50.0   0.560799  \n",
       "22         1  0.000000           20.0   0.927405  \n",
       "23         1  0.000000           20.0   1.000000  \n",
       "24         0  0.834711           20.0   0.441016  \n",
       "25         1  0.033058           20.0   0.306715  \n",
       "26         1  0.016529           20.0   0.457350  \n",
       "27         1  0.000000           60.0   0.442831  \n",
       "28         1  0.016529           50.0   0.373866  \n",
       "29         0  0.272727           50.0   0.304900  "
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "35775633-6559-43f7-9ab0-c78f31c0530e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['rainfall']\n",
    "X = df.drop(columns=['rainfall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "c0db7c4d-20cf-4f84-bf3e-e0f9f9db7186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Convert winddirection back to numeric\n",
    "X['winddirection'] = pd.to_numeric(X['winddirection'], errors='coerce')\n",
    "\n",
    "# Check for any NaN after conversion\n",
    "print(X['winddirection'].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "530ce1c1-376c-429c-80c0-b67d204f6722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "day                int64\n",
       "pressure         float64\n",
       "maxtemp          float64\n",
       "temperature      float64\n",
       "mintemp          float64\n",
       "dewpoint         float64\n",
       "humidity         float64\n",
       "cloud            float64\n",
       "sunshine         float64\n",
       "winddirection    float64\n",
       "windspeed        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "32ec4fc6-0d85-43d6-9c15-f4e5e2b80ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SVM Results ===\n",
      "Accuracy: 0.7534246575342466\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.39      0.44        18\n",
      "           1       0.81      0.87      0.84        55\n",
      "\n",
      "    accuracy                           0.75        73\n",
      "   macro avg       0.66      0.63      0.64        73\n",
      "weighted avg       0.74      0.75      0.74        73\n",
      "\n",
      "[[ 7 11]\n",
      " [ 7 48]]\n",
      "\n",
      "=== Random Forest Results ===\n",
      "Accuracy: 0.7397260273972602\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.44      0.46        18\n",
      "           1       0.82      0.84      0.83        55\n",
      "\n",
      "    accuracy                           0.74        73\n",
      "   macro avg       0.65      0.64      0.64        73\n",
      "weighted avg       0.73      0.74      0.74        73\n",
      "\n",
      "[[ 8 10]\n",
      " [ 9 46]]\n",
      "\n",
      "=== ANN (MLPClassifier) Results ===\n",
      "Accuracy: 0.7123287671232876\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.50      0.46        18\n",
      "           1       0.83      0.78      0.80        55\n",
      "\n",
      "    accuracy                           0.71        73\n",
      "   macro avg       0.63      0.64      0.63        73\n",
      "weighted avg       0.73      0.71      0.72        73\n",
      "\n",
      "[[ 9  9]\n",
      " [12 43]]\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# --- Data Preparation ---\n",
    "\n",
    "# Encode labels if they are categorical\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features (important for SVM and ANN)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# --- 1. Support Vector Machine (SVM) ---\n",
    "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"=== SVM Results ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(confusion_matrix(y_test, y_pred_svm))\n",
    "\n",
    "# --- 2. Random Forest ---\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "print(\"\\n=== Random Forest Results ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "\n",
    "# --- 3. Artificial Neural Network (MLP) ---\n",
    "ann_model = MLPClassifier(hidden_layer_sizes=(64, 32), activation='relu', solver='adam',\n",
    "                          max_iter=500, random_state=42)\n",
    "ann_model.fit(X_train_scaled, y_train)\n",
    "y_pred_ann = ann_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\n=== ANN (MLPClassifier) Results ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_ann))\n",
    "print(classification_report(y_test, y_pred_ann))\n",
    "print(confusion_matrix(y_test, y_pred_ann))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "189ed75e-f8e4-43b5-a4e0-85f5d65c5860",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['rainfall']\n",
    "X = df.drop(columns=['rainfall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "f6b50b22-f7f6-4de4-850e-fc9e936cad5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Convert winddirection back to numeric\n",
    "X['winddirection'] = pd.to_numeric(X['winddirection'], errors='coerce')\n",
    "\n",
    "# Check for any NaN after conversion\n",
    "print(X['winddirection'].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "7e74f3c5-e30d-4961-8d7a-dd7226300849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SVM (RBF) Results ===\n",
      "Accuracy: 0.7534246575342466\n",
      "Misclassification Rate: 0.2465753424657534\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.39      0.44        18\n",
      "           1       0.81      0.87      0.84        55\n",
      "\n",
      "    accuracy                           0.75        73\n",
      "   macro avg       0.66      0.63      0.64        73\n",
      "weighted avg       0.74      0.75      0.74        73\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 7 11]\n",
      " [ 7 48]]\n",
      "\n",
      "=== SVM (Polynomial) Results ===\n",
      "Accuracy: 0.821917808219178\n",
      "Misclassification Rate: 0.17808219178082196\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.39      0.52        18\n",
      "           1       0.83      0.96      0.89        55\n",
      "\n",
      "    accuracy                           0.82        73\n",
      "   macro avg       0.80      0.68      0.70        73\n",
      "weighted avg       0.82      0.82      0.80        73\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 7 11]\n",
      " [ 2 53]]\n",
      "\n",
      "=== Random Forest Results ===\n",
      "Accuracy: 0.7397260273972602\n",
      "Misclassification Rate: 0.26027397260273977\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.44      0.46        18\n",
      "           1       0.82      0.84      0.83        55\n",
      "\n",
      "    accuracy                           0.74        73\n",
      "   macro avg       0.65      0.64      0.64        73\n",
      "weighted avg       0.73      0.74      0.74        73\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 8 10]\n",
      " [ 9 46]]\n",
      "\n",
      "=== ANN (MLPClassifier) Results ===\n",
      "Accuracy: 0.7123287671232876\n",
      "Misclassification Rate: 0.28767123287671237\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.50      0.46        18\n",
      "           1       0.83      0.78      0.80        55\n",
      "\n",
      "    accuracy                           0.71        73\n",
      "   macro avg       0.63      0.64      0.63        73\n",
      "weighted avg       0.73      0.71      0.72        73\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 9  9]\n",
      " [12 43]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# --- Data Preparation ---\n",
    "\n",
    "# Encode labels if they are categorical\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features (important for SVM and ANN)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Function to evaluate model\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test, model_name=\"Model\"):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    misclassification_rate = 1 - accuracy\n",
    "    \n",
    "    print(f\"\\n=== {model_name} Results ===\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Misclassification Rate:\", misclassification_rate)\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    return y_pred\n",
    "\n",
    "# --- 1. SVM with RBF kernel ---\n",
    "svm_rbf = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "evaluate_model(svm_rbf, X_train_scaled, y_train, X_test_scaled, y_test, \"SVM (RBF)\")\n",
    "\n",
    "# --- 2. SVM with Polynomial kernel ---\n",
    "svm_poly = SVC(kernel='poly', degree=3, C=1.0, gamma='scale')  # degree can be tuned\n",
    "evaluate_model(svm_poly, X_train_scaled, y_train, X_test_scaled, y_test, \"SVM (Polynomial)\")\n",
    "\n",
    "# --- 3. Random Forest ---\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "evaluate_model(rf_model, X_train, y_train, X_test, y_test, \"Random Forest\")\n",
    "\n",
    "# --- 4. ANN (MLPClassifier) ---\n",
    "ann_model = MLPClassifier(hidden_layer_sizes=(64, 32), activation='relu', solver='adam',\n",
    "                          max_iter=500, random_state=42)\n",
    "evaluate_model(ann_model, X_train_scaled, y_train, X_test_scaled, y_test, \"ANN (MLPClassifier)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "fe0383bb-aa43-4ab0-a111-ad8342a08792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day                int64\n",
      "pressure         float64\n",
      "maxtemp          float64\n",
      "temperature      float64\n",
      "mintemp          float64\n",
      "dewpoint         float64\n",
      "humidity         float64\n",
      "cloud            float64\n",
      "sunshine         float64\n",
      "winddirection     object\n",
      "windspeed        float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check column types\n",
    "print(X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "becdc98e-659c-4c83-810e-227ef43f99f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day                int64\n",
      "pressure         float64\n",
      "maxtemp          float64\n",
      "temperature      float64\n",
      "mintemp          float64\n",
      "dewpoint         float64\n",
      "humidity         float64\n",
      "cloud            float64\n",
      "rainfall           int64\n",
      "sunshine         float64\n",
      "winddirection    float64\n",
      "windspeed        float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "762d4a7c-dcb5-49de-a00c-384565da6878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Convert winddirection back to numeric\n",
    "X['winddirection'] = pd.to_numeric(X['winddirection'], errors='coerce')\n",
    "\n",
    "# Check for any NaN after conversion\n",
    "print(X['winddirection'].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "bae66b2e-86ca-4e22-a570-29e3fa30e2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "X['winddirection'] = X['winddirection'].fillna(X['winddirection'].mean())\n",
    "print(X['winddirection'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c6edb6-dcb1-4e92-a10a-1c27308931e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e777460d-ad32-4120-baa4-c4f8534324af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddf019e6-fa7c-4ec6-946a-f5cdbfd22859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: Rainfall-tom-ml.csv\n",
      "Shape: (366, 12)\n",
      "Columns: ['day', 'pressure ', 'maxtemp', 'temparature', 'mintemp', 'dewpoint', 'humidity ', 'cloud ', 'rainfall', 'sunshine', '         winddirection', 'windspeed']\n",
      "Parsed date column 'day', unique months: [1]\n",
      "Detected columns: {'rain': 'rainfall', 'rh': 'humidity ', 'tmax': 'maxtemp', 'tmin': 'mintemp', 'pressure': 'pressure ', 'wind_speed': 'windspeed', 'wind_dir': '         winddirection', 'sunshine': 'sunshine'}\n",
      "Using feature columns: ['pressure ', 'humidity ', 'maxtemp', 'mintemp', 'windspeed', '         winddirection', 'sunshine']\n",
      "After dropping missing rows, shape: (365, 8)\n",
      "Final working rows: 0\n",
      "Label distribution:\n",
      " Series([], Name: count, dtype: int64)\n",
      "Minority class ratio: nan\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 7)) while a minimum of 1 is required by MinMaxScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 178\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;66;03m# Min-max scaling (paper used normalization)\u001b[39;00m\n\u001b[0;32m    177\u001b[0m scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n\u001b[1;32m--> 178\u001b[0m X_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(X_all)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m# Train-test split\u001b[39;00m\n\u001b[0;32m    181\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X_scaled, y_all, test_size\u001b[38;5;241m=\u001b[39mTEST_SIZE, random_state\u001b[38;5;241m=\u001b[39mRANDOM_STATE, stratify\u001b[38;5;241m=\u001b[39my_all)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    301\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1098\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1083\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1084\u001b[0m             (\n\u001b[0;32m   1085\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1093\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1094\u001b[0m         )\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1097\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:450\u001b[0m, in \u001b[0;36mMinMaxScaler.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartial_fit(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:490\u001b[0m, in \u001b[0;36mMinMaxScaler.partial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    487\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m    489\u001b[0m first_pass \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 490\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    491\u001b[0m     X,\n\u001b[0;32m    492\u001b[0m     reset\u001b[38;5;241m=\u001b[39mfirst_pass,\n\u001b[0;32m    493\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m_array_api\u001b[38;5;241m.\u001b[39msupported_float_dtypes(xp),\n\u001b[0;32m    494\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    495\u001b[0m )\n\u001b[0;32m    497\u001b[0m data_min \u001b[38;5;241m=\u001b[39m _array_api\u001b[38;5;241m.\u001b[39m_nanmin(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    498\u001b[0m data_max \u001b[38;5;241m=\u001b[39m _array_api\u001b[38;5;241m.\u001b[39m_nanmax(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1072\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1070\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[0;32m   1071\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[1;32m-> 1072\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1073\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1074\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1075\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m   1076\u001b[0m         )\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1079\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 7)) while a minimum of 1 is required by MinMaxScaler."
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "rainfall_ml_pipeline.py\n",
    "\n",
    "Implements the paper's methodology for rainfall prediction using:\n",
    " - Preprocessing (date parsing, optional June-Sep filter, missing handling, feature selection)\n",
    " - Labeling: rainfall >= 2.5 mm -> 1 (rain), else 0 (no rain)\n",
    " - Models: SVM (poly, rbf) and ANN (MLP) as in paper + RandomForest as alternative\n",
    " - Evaluation: accuracy, precision, recall, f1, confusion matrices, feature importances\n",
    " - Outputs saved to outputs/\n",
    "\n",
    "Notes:\n",
    " - The script attempts to auto-detect columns (date/day, rainfall, humidity, maxtemp, mintemp, pressure, windspeed, winddirection).\n",
    " - If you want to force using only June-Sept, set FILTER_JUN_SEP=True\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Optional SMOTE for imbalanced data\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    SMOTE_AVAILABLE = True\n",
    "except Exception:\n",
    "    SMOTE_AVAILABLE = False\n",
    "\n",
    "# ---------------------------\n",
    "# User settings\n",
    "# ---------------------------\n",
    "CSV_PATH = \"Rainfall-tom-ml.csv\"   # input CSV\n",
    "OUTPUT_DIR = \"outputs\"\n",
    "LABEL_THRESHOLD = 2.5             # mm threshold to classify 'rain'\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "FILTER_JUN_SEP = False            # set True to force filtering to June-Sept if months present\n",
    "USE_SMOTE = False                 # set True to apply SMOTE if imbalanced (requires imbalanced-learn)\n",
    "\n",
    "# Create output folder\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ---------------------------\n",
    "# Utility functions\n",
    "# ---------------------------\n",
    "def find_col_like(cols, keywords):\n",
    "    \"\"\"Return first column name that matches any keyword (case-insensitive substring).\"\"\"\n",
    "    for c in cols:\n",
    "        lc = c.lower()\n",
    "        for kw in keywords:\n",
    "            if kw in lc:\n",
    "                return c\n",
    "    return None\n",
    "\n",
    "def save_report(df_summary, out_dir=OUTPUT_DIR):\n",
    "    csvp = os.path.join(out_dir, \"model_results_summary.csv\")\n",
    "    df_summary.to_csv(csvp, index=False)\n",
    "    print(\"Saved summary:\", csvp)\n",
    "\n",
    "def plot_confusion(cm, labels, title, out_path):\n",
    "    plt.figure(figsize=(4,3))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path)\n",
    "    plt.close()\n",
    "\n",
    "# ---------------------------\n",
    "# Load dataset\n",
    "# ---------------------------\n",
    "print(\"Loading:\", CSV_PATH)\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Columns:\", list(df.columns))\n",
    "\n",
    "# Try to find date/day column and parse month\n",
    "date_col = find_col_like(df.columns, [\"date\", \"day\", \"time\"])\n",
    "if date_col:\n",
    "    try:\n",
    "        df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "        df['month'] = df[date_col].dt.month\n",
    "        print(f\"Parsed date column '{date_col}', unique months: {sorted(df['month'].dropna().unique())}\")\n",
    "    except Exception:\n",
    "        print(f\"Could not parse {date_col} as datetime; continuing without month info.\")\n",
    "else:\n",
    "    print(\"No date-like column detected.\")\n",
    "\n",
    "# Auto-detect relevant columns (common names)\n",
    "rain_col = find_col_like(df.columns, [\"rain\", \"rainfall\", \"precip\"])\n",
    "rh_col = find_col_like(df.columns, [\"rh\", \"humidity\", \"humid\"])\n",
    "tmax_col = find_col_like(df.columns, [\"tmax\", \"max temp\", \"maxtemp\", \"maximum temperature\"])\n",
    "tmin_col = find_col_like(df.columns, [\"tmin\", \"min temp\", \"mintemp\", \"minimum temperature\"])\n",
    "slp_col = find_col_like(df.columns, [\"slp\", \"pressure\", \"sea level pressure\", \"mslp\"])\n",
    "wind_spd_col = find_col_like(df.columns, [\"windspeed\", \"wind speed\", \"wind_spd\"])\n",
    "wind_dir_col = find_col_like(df.columns, [\"winddirection\", \"wind direction\", \"wind_dir\", \"wd\"])\n",
    "sun_col = find_col_like(df.columns, [\"sun\", \"sunshine\"])\n",
    "\n",
    "detected = {\n",
    "    \"rain\": rain_col, \"rh\": rh_col, \"tmax\": tmax_col, \"tmin\": tmin_col,\n",
    "    \"pressure\": slp_col, \"wind_speed\": wind_spd_col, \"wind_dir\": wind_dir_col, \"sunshine\": sun_col\n",
    "}\n",
    "print(\"Detected columns:\", detected)\n",
    "\n",
    "# Ensure rainfall exists\n",
    "if not rain_col:\n",
    "    raise RuntimeError(\"No rainfall/precipitation column found in CSV. Please provide a column named 'rain', 'rainfall', or similar.\")\n",
    "\n",
    "# Build feature list in the priority order (paper used pressure, RH, Tmax, Tmin, winds)\n",
    "feature_cols = [c for c in [slp_col, rh_col, tmax_col, tmin_col, wind_spd_col, wind_dir_col, sun_col] if c is not None]\n",
    "\n",
    "if len(feature_cols) == 0:\n",
    "    raise RuntimeError(\"No candidate feature columns detected. Please check CSV headers.\")\n",
    "\n",
    "print(\"Using feature columns:\", feature_cols)\n",
    "\n",
    "# Subset working DF\n",
    "df_work = df[feature_cols + [rain_col]].copy()\n",
    "\n",
    "# Drop rows with all features missing or rainfall missing\n",
    "df_work = df_work.dropna(subset=[rain_col], how='any')\n",
    "df_work = df_work.dropna(subset=feature_cols, how='any')\n",
    "\n",
    "print(\"After dropping missing rows, shape:\", df_work.shape)\n",
    "\n",
    "# If month exists and user requested filter, apply filter (but only if it gives enough rows)\n",
    "if 'month' in df.columns and FILTER_JUN_SEP:\n",
    "    idx = df[df['month'].isin([6,7,8,9])].index\n",
    "    if len(idx) >= 30:\n",
    "        df_work = df.loc[idx, feature_cols + [rain_col]].dropna(subset=feature_cols + [rain_col], how='any')\n",
    "        print(\"Filtered to June-Sep, rows:\", df_work.shape[0])\n",
    "    else:\n",
    "        print(\"June-Sep subset too small; skipping filter and using full dataset.\")\n",
    "\n",
    "# Convert columns to numeric where possible\n",
    "for c in feature_cols + [rain_col]:\n",
    "    df_work[c] = pd.to_numeric(df_work[c], errors='coerce')\n",
    "\n",
    "# After conversion, drop any rows with NaNs in features or rain\n",
    "df_work = df_work.dropna(subset=feature_cols + [rain_col], how='any')\n",
    "print(\"Final working rows:\", df_work.shape[0])\n",
    "\n",
    "# Encode wind direction if present and non-numeric\n",
    "if wind_dir_col and df_work[wind_dir_col].dtype == object:\n",
    "    le = LabelEncoder()\n",
    "    df_work[wind_dir_col] = le.fit_transform(df_work[wind_dir_col].astype(str))\n",
    "    print(\"Encoded wind direction: classes =\", list(le.classes_))\n",
    "\n",
    "# ---------------------------\n",
    "# Labeling\n",
    "# ---------------------------\n",
    "df_work['label'] = (df_work[rain_col] >= LABEL_THRESHOLD).astype(int)\n",
    "print(\"Label distribution:\\n\", df_work['label'].value_counts())\n",
    "\n",
    "# Check for class balance\n",
    "counts = df_work['label'].value_counts()\n",
    "minority_ratio = counts.min() / counts.sum()\n",
    "print(f\"Minority class ratio: {minority_ratio:.3f}\")\n",
    "\n",
    "# Optionally apply SMOTE if requested and available\n",
    "X_all = df_work[feature_cols].values\n",
    "y_all = df_work['label'].values\n",
    "\n",
    "# Min-max scaling (paper used normalization)\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_all)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_all, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y_all)\n",
    "print(\"Train/test split:\", X_train.shape, X_test.shape)\n",
    "\n",
    "if USE_SMOTE:\n",
    "    if not SMOTE_AVAILABLE:\n",
    "        print(\"SMOTE requested but imbalanced-learn not installed. Skip SMOTE.\")\n",
    "    else:\n",
    "        sm = SMOTE(random_state=RANDOM_STATE)\n",
    "        X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "        print(\"Applied SMOTE. New train distribution:\", np.bincount(y_train))\n",
    "\n",
    "# ---------------------------\n",
    "# Models\n",
    "# ---------------------------\n",
    "\n",
    "results = []\n",
    "\n",
    "def evaluate_and_record(model, name):\n",
    "    print(f\"Training {name} ...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    print(f\"{name} -> Acc: {acc:.4f}, Prec: {prec:.4f}, Rec: {rec:.4f}, F1: {f1:.4f}\")\n",
    "    results.append({\"model\": name, \"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"cm\": cm})\n",
    "    # save confusion\n",
    "    plot_confusion(cm, labels=[\"no-rain\",\"rain\"], title=name + \" Confusion\", out_path=os.path.join(OUTPUT_DIR, f\"cm_{name.replace(' ','_')}.png\"))\n",
    "    return model\n",
    "\n",
    "# 1) SVM per paper: polynomial kernel (degree 3) and RBF\n",
    "svm_poly = SVC(kernel='poly', degree=3, C=1, probability=False, random_state=RANDOM_STATE)\n",
    "svm_rbf = SVC(kernel='rbf', C=1, probability=False, random_state=RANDOM_STATE)\n",
    "\n",
    "# 2) ANN per paper: three-layer (input-hidden-output). We'll use one hidden layer with small units to match \"4 neurons\" reference\n",
    "ann = MLPClassifier(hidden_layer_sizes=(4,), activation='relu', solver='adam', max_iter=1000, random_state=RANDOM_STATE)\n",
    "\n",
    "# 3) Alternative: Random Forest\n",
    "# Justification (in code comment):\n",
    "# Random Forest is chosen as an alternative because:\n",
    "#  - it handles non-linear relationships well,\n",
    "#  - is robust to outliers and noisy features,\n",
    "#  - gives feature importance (helpful interpretation),\n",
    "#  - handles tabular data generally well without heavy feature engineering,\n",
    "#  - can handle imbalanced classes with class_weight or sampling.\n",
    "rf = RandomForestClassifier(n_estimators=200, class_weight='balanced', random_state=RANDOM_STATE)\n",
    "\n",
    "# Train and evaluate\n",
    "svm_poly = evaluate_and_record(svm_poly, \"SVM_Poly_deg3\")\n",
    "svm_rbf  = evaluate_and_record(svm_rbf, \"SVM_RBF\")\n",
    "ann = evaluate_and_record(ann, \"ANN_MLP\")\n",
    "rf = evaluate_and_record(rf, \"RandomForest\")\n",
    "\n",
    "# Feature importances for RF\n",
    "if hasattr(rf, \"feature_importances_\"):\n",
    "    fi = pd.Series(rf.feature_importances_, index=feature_cols).sort_values(ascending=False)\n",
    "    print(\"\\nRandom Forest feature importances:\\n\", fi)\n",
    "    fi.to_csv(os.path.join(OUTPUT_DIR, \"random_forest_feature_importances.csv\"))\n",
    "\n",
    "# Save model evaluation summary CSV\n",
    "summary_rows = []\n",
    "for r in results:\n",
    "    summary_rows.append({\n",
    "        \"model\": r[\"model\"],\n",
    "        \"accuracy\": r[\"accuracy\"],\n",
    "        \"precision\": r[\"precision\"],\n",
    "        \"recall\": r[\"recall\"],\n",
    "        \"f1\": r[\"f1\"]\n",
    "    })\n",
    "df_summary = pd.DataFrame(summary_rows).sort_values(by=\"f1\", ascending=False)\n",
    "save_report(df_summary, out_dir=OUTPUT_DIR)\n",
    "print(\"\\nSaved confusion matrices and summary to\", OUTPUT_DIR)\n",
    "\n",
    "# Save scaled dataset used for training (optional)\n",
    "df_scaled = pd.DataFrame(X_scaled, columns=feature_cols)\n",
    "df_scaled['label'] = y_all\n",
    "df_scaled.to_csv(os.path.join(OUTPUT_DIR, \"scaled_dataset_used.csv\"), index=False)\n",
    "print(\"Saved scaled dataset to outputs/scaled_dataset_used.csv\")\n",
    "\n",
    "# Print classification reports to text file\n",
    "with open(os.path.join(OUTPUT_DIR, \"classification_reports.txt\"), \"w\") as fh:\n",
    "    for r in results:\n",
    "        fh.write(f\"=== {r['model']} ===\\n\")\n",
    "        # Re-compute classification report\n",
    "        # we trained earlier; get predictions again\n",
    "        model_name = r['model']\n",
    "        if model_name.startswith(\"SVM_Poly\"):\n",
    "            pred = svm_poly.predict(X_test)\n",
    "        elif model_name.startswith(\"SVM_RBF\"):\n",
    "            pred = svm_rbf.predict(X_test)\n",
    "        elif model_name.startswith(\"ANN\"):\n",
    "            pred = ann.predict(X_test)\n",
    "        elif model_name.startswith(\"RandomForest\"):\n",
    "            pred = rf.predict(X_test)\n",
    "        else:\n",
    "            continue\n",
    "        fh.write(classification_report(y_test, pred, digits=4))\n",
    "        fh.write(\"\\n\\n\")\n",
    "print(\"Saved classification reports.\")\n",
    "\n",
    "# Final message and quick printout of summary\n",
    "print(\"\\n--- Model summary ---\")\n",
    "print(df_summary.to_string(index=False))\n",
    "print(\"\\nAll done. Inspect the 'outputs' folder for results, plots, and saved CSVs.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29a427d-bc74-4579-9696-3f0aeb462d15",
   "metadata": {},
   "source": [
    "Short justification for the chosen alternative model (Random Forest)\n",
    "\n",
    "Random Forests are a strong baseline for tabular, meteorological predictors because they naturally capture nonlinear interactions, handle mixed-data types, are robust to noise/outliers, and provide feature importances which help interpret which atmospheric variables matter most. Compared with SVM and ANN, Random Forests typically require less hyperparameter tuning to reach solid performance on small-to-medium datasets  making them a sensible, justified alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4334ddf5-edb1-44fc-a4b4-7d865ea1d846",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
